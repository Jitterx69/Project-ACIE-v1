apiVersion: apps/v1
kind: Deployment
metadata:
  name: acie-inference
  namespace: acie
  labels:
    app: acie
    component: inference
spec:
  replicas: 3
  selector:
    matchLabels:
      app: acie
      component: inference
  template:
    metadata:
      labels:
        app: acie
        component: inference
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      containers:
        - name: acie-server
          image: acie/inference:latest
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: CUDA_VISIBLE_DEVICES
              value: "0"
            - name: MODEL_PATH
              value: "/models/acie_final.ckpt"
            - name: CONFIG_PATH
              value: "/config/gpu_config.yaml"
            - name: REDIS_HOST
              value: "redis-service"
            - name: REDIS_PORT
              value: "6379"
            - name: POSTGRES_HOST
              value: "postgres-service"
            - name: POSTGRES_PORT
              value: "5432"
            - name: POSTGRES_DB
              valueFrom:
                configMapKeyRef:
                  name: acie-config
                  key: postgres_db
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: acie-secrets
                  key: postgres_user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: acie-secrets
                  key: postgres_password
          resources:
            requests:
              memory: "8Gi"
              cpu: "4"
              nvidia.com/gpu: "1"
            limits:
              memory: "16Gi"
              cpu: "8"
              nvidia.com/gpu: "1"
          volumeMounts:
            - name: model-storage
              mountPath: /models
              readOnly: true
            - name: config-storage
              mountPath: /config
              readOnly: true
            - name: logs-storage
              mountPath: /app/logs
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
      volumes:
        - name: model-storage
          persistentVolumeClaim:
            claimName: acie-models-pvc
        - name: config-storage
          configMap:
            name: acie-config-files
        - name: logs-storage
          emptyDir: {}
      nodeSelector:
        nvidia.com/gpu.present: "true"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
---
apiVersion: v1
kind: Service
metadata:
  name: acie-service
  namespace: acie
  labels:
    app: acie
    component: inference
spec:
  selector:
    app: acie
    component: inference
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 8080
    - name: grpc
      protocol: TCP
      port: 50051
      targetPort: 50051
  type: LoadBalancer
  sessionAffinity: ClientIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: acie-hpa
  namespace: acie
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: acie-inference
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 50
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
        - type: Percent
          value: 100
          periodSeconds: 60
        - type: Pods
          value: 2
          periodSeconds: 60
      selectPolicy: Max
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: acie-models-pvc
  namespace: acie
spec:
  accessModes:
    - ReadOnlyMany
  resources:
    requests:
      storage: 50Gi
  storageClassName: fast-ssd
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: acie-config
  namespace: acie
data:
  postgres_db: "acie_db"
  redis_host: "redis-service"
  redis_port: "6379"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: acie-config-files
  namespace: acie
data:
  gpu_config.yaml: |
    # GPU configuration is mounted from this ConfigMap
    # Inline the contents of config/gpu_config.yaml here
