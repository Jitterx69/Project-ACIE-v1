{
    "annotations": {
        "list": [
            {
                "builtIn": 1,
                "datasource": "-- Grafana --",
                "enable": true,
                "hide": true,
                "iconColor": "rgba(0, 211, 255, 1)",
                "name": "Annotations & Alerts",
                "type": "dashboard"
            }
        ]
    },
    "editable": true,
    "gnetId": null,
    "graphTooltip": 0,
    "id": 1,
    "links": [],
    "panels": [
        {
            "datasource": "Prometheus",
            "gridPos": {
                "h": 8,
                "w": 12,
                "x": 0,
                "y": 0
            },
            "id": 2,
            "options": {
                "legend": {
                    "calcs": [],
                    "displayMode": "list",
                    "placement": "bottom"
                },
                "tooltip": {
                    "mode": "single"
                }
            },
            "targets": [
                {
                    "expr": "rate(acie_requests_total[1m])",
                    "legendFormat": "{{method}} {{endpoint}}",
                    "refId": "A"
                }
            ],
            "title": "Request Rate",
            "type": "timeseries"
        },
        {
            "datasource": "Prometheus",
            "gridPos": {
                "h": 8,
                "w": 12,
                "x": 12,
                "y": 0
            },
            "id": 4,
            "options": {
                "legend": {
                    "calcs": [],
                    "displayMode": "list",
                    "placement": "bottom"
                },
                "tooltip": {
                    "mode": "single"
                }
            },
            "targets": [
                {
                    "expr": "histogram_quantile(0.95, rate(acie_inference_latency_seconds_bucket[5m]))",
                    "legendFormat": "P95 Latency",
                    "refId": "A"
                }
            ],
            "title": "Inference Latency (P95)",
            "type": "timeseries"
        },
        {
            "datasource": "Prometheus",
            "gridPos": {
                "h": 8,
                "w": 8,
                "x": 0,
                "y": 8
            },
            "id": 6,
            "options": {
                "reduceOptions": {
                    "calcs": [
                        "lastNotNull"
                    ],
                    "fields": "",
                    "values": false
                },
                "showThresholdLabels": false,
                "showThresholdMarkers": true
            },
            "targets": [
                {
                    "expr": "acie_gpu_utilization_percent",
                    "legendFormat": "GPU {{gpu_id}}",
                    "refId": "A"
                }
            ],
            "title": "GPU Utilization",
            "type": "gauge"
        },
        {
            "datasource": "Prometheus",
            "gridPos": {
                "h": 8,
                "w": 8,
                "x": 8,
                "y": 8
            },
            "id": 8,
            "options": {
                "reduceOptions": {
                    "calcs": [
                        "lastNotNull"
                    ],
                    "fields": "",
                    "values": false
                }
            },
            "targets": [
                {
                    "expr": "acie_gpu_memory_mb",
                    "legendFormat": "GPU {{gpu_id}}",
                    "refId": "A"
                }
            ],
            "title": "GPU Memory Usage (MB)",
            "type": "gauge"
        },
        {
            "datasource": "Prometheus",
            "gridPos": {
                "h": 8,
                "w": 8,
                "x": 16,
                "y": 8
            },
            "id": 10,
            "options": {
                "reduceOptions": {
                    "calcs": [
                        "lastNotNull"
                    ],
                    "fields": "",
                    "values": false
                }
            },
            "targets": [
                {
                    "expr": "acie_cache_hit_rate_percent",
                    "legendFormat": "Hit Rate",
                    "refId": "A"
                }
            ],
            "title": "Cache Hit Rate",
            "type": "gauge"
        },
        {
            "datasource": "Prometheus",
            "gridPos": {
                "h": 8,
                "w": 24,
                "x": 0,
                "y": 16
            },
            "id": 12,
            "options": {
                "legend": {
                    "calcs": [],
                    "displayMode": "list",
                    "placement": "bottom"
                }
            },
            "targets": [
                {
                    "expr": "rate(acie_requests_total{status=~\"5..\"}[1m])",
                    "legendFormat": "{{endpoint}}",
                    "refId": "A"
                }
            ],
            "title": "Error Rate (5xx)",
            "type": "timeseries"
        }
    ],
    "schemaVersion": 30,
    "style": "dark",
    "tags": [
        "acie",
        "inference"
    ],
    "templating": {
        "list": []
    },
    "time": {
        "from": "now-1h",
        "to": "now"
    },
    "timepicker": {},
    "timezone": "",
    "title": "ACIE Inference Overview",
    "uid": "acie-overview",
    "version": 1
}