# Walkthrough: R Module Expansion (ACIEr)

I have successfully transformed the experimental R scripts into a robust **R Package (`ACIEr`)** and expanded it with advanced statistical capabilities.

## Changes

### 1. Package Structure
Refactored the `r/` directory into a formal package:
- **`r/DESCRIPTION`**: Defines dependencies (`reticulate`, `lme4`, `spatstat`, `rmarkdown`) and metadata.
- **`r/NAMESPACE`**: Manages exported functions.
- **`r/R/`**: Modular source code.

### 2. Core Analysis Features
- **Latent Space Visualization**: `plot_latent_space()` (PCA/t-SNE).
- **Sensitivity Analysis**: `sensitivity_analysis()` for counterfactual robustness.
- **Diagnostics**: `check_residuals()` for VAE validation.

### 3. Advanced Statistical Capabilities
- **Hierarchical Modeling**: `fit_hierarchical_model()` uses `lme4` to fit mixed-effects models (e.g., galaxies nested in clusters).
- **Spatial Analysis**: `calculate_spatial_correlation()` computes the 2-Point Correlation Function ($\xi(r)$) using `spatstat`.
- **Automated Reporting**: `generate_report()` renders a parameterized HTML report (`inst/rmd/analysis_report.Rmd`) summarizing the entire analysis pipeline.

### 4. Reliability & Usage
- **Unit Tests**: `tests/testthat/` suite covers core and advanced features.
- **Endurance Test**: `r/stress_test.R` performs long-running stability checks (usage/memory).
- **Dashboard**: Shiny app moved to `inst/shiny/app.R` and updated to use the package.

## Usage Guide

```r
library(ACIEr)

# 1. Load Model & Data
model <- load_acie_model("model.ckpt")
data <- read.csv("observations.csv")

# 2. Visualize Latent Space
plot_latent_space(model, data, method="tsne")

# 3. Fit Mixed-Effects Model
mixed_model <- fit_hierarchical_model(data, "mass ~ metallicity + (1|cluster_id)")
summary(mixed_model)

# 4. Generate Report
generate_report("analysis.html", "model.ckpt", "observations.csv")
```

## Running Tests

### Unit Tests
```bash
Rscript -e "devtools::test('r/')"
```

### Endurance Test
```bash
# Install dependencies first (takes time)
Rscript r/install_deps.R
# Install package
R CMD INSTALL -l r-libs r/
# Run test
Rscript r/stress_test.R
```
# Walkthrough: Java Module Expansion

In addition to the R package, I have transformed the **Java Module** into an enterprise-grade microservice.

## Changes

### 1. Security (Spring Security)
- **JWT Authentication**: Implemented `JwtTokenProvider` to issue and validate tokens.
- **Filter Chain**: Configured `SecurityConfig` to protect `/api/**` endpoints.
- **Login**: Added `AuthController` for token issuance.

### 2. Persistence & Auditing
- **Database**: Integrated **H2** (runtime) and **JPA**.
- **Logging**: Created `InferenceLog` entity to track every request (timestamp, duration, status, input hash).
- **Service**: Implemented `AuditService` to asynchronously save logs without blocking the response.

### 3. High-Performance Integration
- **Async Processing**: Enabled `@EnableAsync` and configured `ThreadPoolTaskExecutor` for non-blocking inference.
- **gRPC Client**: implemented `GrpcInferenceClient` using `acie.proto` to communicate with the Python engine (requires `mvn compile` to generate stubs).

## Verification
- Added **JUnit 5** sanity test (`AcieServerApplicationTests`).
- Validated `pom.xml` dependency tree.

# Walkthrough: Frontend Dashboard Expansion

I have upgraded the **React Dashboard** to visualize cross-component metrics.

## Changes

### 1. API Layer
- **`javaService.js`**: Fetches real-time inference audit logs from the Java Microservice.
- **`rService.js`**: Retrieves statistical plots generated by the R analysis pipeline.

### 2. New Components
- **AuditLogTable.jsx**: A live table displaying:
    - Status (Success/Fail) with icons.
    - Latency (ms).
    - Input Hash (for verification).
- **LatentSpaceVisualizer.jsx**:
    - Displays R-generated plots (PCA/t-SNE).
    - Includes a real-time scatter plot placeholder for live projection.
- **Loading States**: Added spinners for better UX during data fetching.

### 3. Integration
- Updated `App.jsx` to include these components below the main metrics grid, providing a unified view of the system's performance and analytical output.

# Walkthrough: Server Operations Module

I have established a robust **Containerization & Orchestration** layer to manage the entire ACIE stack.

## Changes

### 1. Containerization
- **Java Gateway**: Created `java/Dockerfile` (Multi-stage Maven build -> OpenJDK runtime).
- **Frontend**: Created `frontend/Dockerfile` (Node build -> Nginx serving static assets).
- **Inference Engine**: Updated `Dockerfile.production` to include `r-base` for the R statistical module.

### 2. Orchestration (`docker-compose.production.yml`)
- Added `acie-java` service (Internal Port 8080).
- Added `acie-frontend` service (Internal Port 80).
- Updated `nginx` configuration to route:
    - `/` -> `acie-frontend`
    - `/api/java` -> `acie-java`
    - `/api/v2` -> `acie-api`

### 3. Management Scripts (`ops/`)
- `start.sh`: Builds and starts the entire stack in detached mode.
- `stop.sh`: Gracefully shuts down all services.
- `status.sh`: Displays the health of running containers.

## Usage
```bash
./ops/start.sh
# Access Dashboard at http://localhost
```

# Walkthrough: Kubernetes Orchestration

I have generated a complete set of **Kubernetes Manifests** to deploy ACIE as a cloud-native application.

## Changes

### 1. Infrastructure (`k8s/`)
- **Redis**: `redis.yaml` (Deployment + Service).
- **Postgres**: `postgres.yaml` (StatefulSet + PVC).

### 2. Microservices
- **Java Gateway**: `java-deployment.yaml` deploys the Spring Boot container.
- **Frontend**: `frontend-deployment.yaml` deploys the Nginx/React container.
- **Inference Engine**: Existing `deployment.yaml` was reviewed and is compatible.

### 3. Networking
- **Ingress**: Updated `ingress.yaml` to route traffic to all three services based on path (`/`, `/api/java`, `/api/v2`).

## Deployment
See `k8s/README.md` for step-by-step instructions.

# Walkthrough: Rust Accelerator

I have enhanced the **Rust Core (`acie_core`)** with high-performance primitives for sparse data and privacy.

## Changes

### 1. Sparse Matrix Kernel (`rust/src/sparse.rs`)
- **`SparseMatrix`**: A new Python class implementing the CSR (Compressed Sparse Row) format.
- **Performance**: Uses `rayon` for parallel SpMM (Sparse-Dense Matrix Multiplication), critical for graph neural networks.

### 2. Cryptographic Primitives (`rust/src/acie_crypto.rs`)
- **Batch Encryption**: `encrypt_batch` processes vectors in parallel.
- **Homomorphic Dot Product**: `dot_product` enables privacy-preserving linear algebra directly on ciphertexts.

## Verification
The Rust extension compiles successfully with `cargo build --release`. 
To use in Python:
```python
from acie_core import SparseMatrix, RustPaillier
```

# Walkthrough: Database Engineering

I have unified the storage layer into a single **PostgreSQL** instance enhanced with efficient extensions.

## Changes

### 1. Infrastructure (`database/`)
-   **Unified DB**: Custom Docker image (`database/Dockerfile`) combining PostgreSQL with **`pgvector`**.
-   **Schema**: `schema.sql` defines:
    -   `users`: Relational auth data.
    -   `inference_logs`: Metric storage.
    -   `documents`: Vector store with `vector(768)` column and HNSW indexing.

### 2. Integration (`acie/db/`)
-   **`vector_store.py`**: Python abstraction using `pgvector.sqlalchemy` to store and search embeddings using Cosine Similarity.
-   **Dependencies**: Added `pgvector` and `psycopg2-binary` to `requirements.txt`.

## Benefits
-   **Simplicity**: One database technology to manage.
-   **Performance**: Localized vector search without network overhead to a separate vector DB.

# Walkthrough: RAG Pipeline

I have integrated the **Retrieval-Augmented Generation (RAG)** pipeline with the Postgres Vector Store.

## Changes

### 1. Retrieval Strategy (`acie/rag/retrieval.py`)
-   **`PGVectorRetriever`**: Connects to the database to fetch context.
-   **Logic**: Converts retrieved embeddings directly into tensor modules for the Secure Generation Model.

### 2. Pipeline (`acie/rag/pipeline.py`)
-   **Configuration**: Defaults to `PGVectorRetriever` when `RAG_RETRIEVER_TYPE=pgvector` is set.
-   **Flow**: 
    1.  Encrypted Image Input.
    2.  Vector Search for Context (using query embedding).
    3.  Secure Generation (Image + Context).
    4.  Decryption.

## Verification
I created and passed a unit test `tests/test_rag_pipeline.py` that verifies:
-   Initialization of `PGVectorRetriever`.
-   Correct calling of `VectorStore.search`.
-   Injection of retrieved context into the generation model.

